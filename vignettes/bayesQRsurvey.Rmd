---
title: "bayesQRsurvey"
author: "bayesQRsurvey Package"
date: "`r Sys.Date()`"
output: 
    rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{bayesQRsurvey}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  fig.width = 7,
  fig.height = 5
)
```

## Introduction

[![CRAN status](https://www.r-pkg.org/badges/version/bayesQRsurvey)](https://CRAN.R-project.org/package=bayesQRsurvey)

<div style="display: flex; align-items: center;">

<div style="flex: 0 0 200px; padding-right: 20px;">
  <img src="logo_tau.png" width="180" alt="bayesQRsurvey logo"/>
</div>

<div style="flex: 1;">
The **bayesQRsurvey** package implements four approaches for Bayesian weighted quantile regression:

- **Asymmetric Laplace Distribution (ALD)**: Uses the ALD as a working likelihood, incorporating survey weights in the scale parameter. Posterior inference is carried out via Gibbs sampling.  
- **Score**: Builds a working likelihood from estimating equations (score function), following Huang, Xu and Tashnev (2015). It accounts for survey weights and uses adaptive Metropolis–Hastings for inference.  
- **Approximate**: Proposed by Wang, Kim and Yang (2018), this method approximates the posterior using the sampling distribution of summary statistics. The Score-based method is a special case, also using adaptive Metropolis–Hastings.  
- **Expectation–Maximization (EM) Algorithm**: Implemented for multivariate quantile regression. It leverages the ALD mixture representation to update latent variables and parameters iteratively, targeting posterior modes with much lower computational cost than MCMC.  
</div>

</div>

### Model specification in `bqr.svy`

The `bqr.svy` function can estimate three types of models, where the quantile regression coefficients are defined at the **super-population level**, and their estimators are built upon the **survey weights**.

---

#### 1. Asymmetric Laplace Distribution (method = `'ald'`)

Based on a survey-weighted estimator given by:

\[
\underset{\boldsymbol{\beta}(\tau) \in \mathbb{R}^{p}}{\operatorname{argmin}}
\sum_{i \in S} w_i \, \rho_{\tau}\!\left( y_i - \mathbf{x}_i^{\top} \boldsymbol{\beta}(\tau) \right)
\tag{1}
\]

and using the equivalence with the Asymmetric Laplace Distribution (ALD), the likelihood function is:

\[
\mathcal{L}(\boldsymbol{\beta}(\tau), \sigma; \mathbf{y}, \mathbf{X}, \mathbf{w}) =
\prod_{i \in S} w_i \,
\frac{\tau (1 - \tau)}{\sigma}
\exp \left\{
- w_i \, \rho_{\tau}\!\left( \frac{y_i - \mathbf{x}_i^{\top} \boldsymbol{\beta}(\tau)}{\sigma} \right)
\right\}
\tag{2}
\]

**Prior distributions:**

\[
\boldsymbol{\beta}(\tau) \sim \mathcal{N}(\text{mean}=\text{beta\_x\_mean},\, \text{sd}=\text{beta\_x\_cov}), \quad
\sigma \sim \text{Inv-Gamma}(\text{shape}=\text{sigma\_shape},\, \text{rate}=\text{sigma\_rate})
\]

---

#### 2. Score-based methods

Two alternative approaches are used, both relying on **survey-weighted estimating functions**:

\[
U_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right) =
\sum_{i \in \mathcal{S}} w_i \, \mathbf{x}_i \, \psi_{\tau}\!\left( y_i - \mathbf{x}_i^{\top} \boldsymbol{\beta}(\tau) \right)
\tag{3}
\]

##### (a) Score-based likelihood (method = `'score'`)

\[
\mathcal{L}(\boldsymbol{\beta}(\tau); \mathbf{y}, \mathbf{X}, \mathbf{w}) =
C \exp \left\{
-\frac{1}{2n} \,
U_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right)^{\top}
\Omega_{1}
U_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right)
\right\}
\tag{4}
\]

##### (b) Gaussian pseudolikelihood approximation (method = `'approximate'`)

\[
\mathcal{L}(\boldsymbol{\beta}(\tau); \mathbf{y}, \mathbf{X}, \mathbf{w}) =
\exp \left\{
-\frac{1}{2} \,
\tilde{U}_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right)^{\top}
\Omega_{2}^{-1}
\tilde{U}_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right)
- \frac{1}{2} \log \!\left| (2\pi)\Omega_{2} \right|
\right\}
\tag{5}
\]

where

\[
\tilde{U}_{\mathcal{S}}\!\left( \boldsymbol{\beta}(\tau) \right)
= \sum_{i \in \mathcal{S}} \tilde{w}_i \, \mathbf{x}_i \, \psi_{\tau}\!\left( y_i - \mathbf{x}_i^{\top} \boldsymbol{\beta}(\tau) \right)
\]

**Prior distribution:**

\[
\boldsymbol{\beta}(\tau) \sim \mathcal{N}(\text{mean}=\text{beta\_x\_mean},\, \text{sd}=\text{beta\_x\_cov})
\]

Also, this vignette compares the performance of **bayesQR** with the three MCMC methods implemented in **bayesQRsurvey** using a simulated dataset and the Prostate cancer dataset included in the `bayesQR` package.  
We estimate the 25th, 50th, and 75th quantile and compare coefficient estimates across all methods.



## bayesQRsurvey usage examples

Let's begin showing how to use bayesQRsurvey methods:

```{r}
library(bayesQRsurvey)
```

### Creating Priors

The `prior()` function provides a unified interface to define prior
distributions for both **univariate** (`bqr.svy`) and **multivariate**
(`mo.bqr.svy`) Bayesian quantile regression models.

It returns an **S3 object** that store the prior information in a structured
way. 

> The `prior()` function creates an S3 object of class `bqr_prior` that
> contains the prior information. If the object is omitted in a call to
> `bqr.svy()` or `mo.bqr.svy()`, a **standard vague prior** is used by default.

Doing an example using bayesQRsurvey

```{r prior-examples}
my_prior <- bayesQRsurvey::prior(
  beta_x_mean = rep(0, 4),              
  beta_x_cov  = diag(1000, 4),          
  sigma_shape = 0.001,                  
  sigma_rate  = 0.001                   
)

print(my_prior)
```


### Fitting models with different methods

We use the **mtcars** dataset to fit three models — **ALD**, **Score**, and **Approximate** — each at the 0.5 quantile.

```{r method-examples}
set.seed(123)

data(mtcars)

mtcars_scaled <- mtcars
mtcars_scaled[, c("wt", "hp", "cyl")] <- scale(mtcars[, c("wt", "hp", "cyl")])

form <- mpg ~ wt + hp + cyl

fit_ald <- bqr.svy(
  form,
  data      = mtcars_scaled,
  quantile  = 0.5,
  method    = "ald",
  niter     = 20000,
  burnin    = 10000,
  thin      = 5,
  prior     = my_prior,
  verbose   = FALSE
)

fit_score <- bqr.svy(
  form,
  data      = mtcars_scaled,
  quantile  = 0.5,
  method    = "score",
  niter     = 25000,    
  burnin    = 13000,
  prior     = my_prior, 
  thin      = 5,
  verbose   = FALSE
)

fit_approx <- bqr.svy(
  form,
  data      = mtcars_scaled,
  quantile  = 0.5,
  method    = "approximate",
  niter     = 25000,
  burnin    = 13000,
  prior     = my_prior,
  thin      = 5,
  verbose   = FALSE
)


```

For the EM algorithm, the model is fitted by projecting the multivariate response onto a set of directions. These directions can be supplied by the user through an object `U`; if not provided, the algorithm will automatically generate them.

```{r}
data(mtcars)

Y <- cbind(mtcars$mpg, mtcars$hp)

set.seed(123)
d <- ncol(Y)
n_dir <- 3
U <- matrix(NA_real_, d, n_dir)
for (k in 1:n_dir) {
  u_k <- rnorm(d)
  U[, k] <- u_k / sqrt(sum(u_k^2))
}

fit_mo <- mo.bqr.svy(
  cbind(mpg, hp) ~ wt + cyl + disp,
  data     = mtcars,
  quantile = c(0.25, 0.5, 0.75),
  U        = U,         
  prior    = my_prior,
  n_dir    = n_dir,
  max_iter = 5000,     
  verbose  = FALSE
)


gamma_U <- vector("list", n_dir)
for (k in 1:n_dir) {
  gamma_U[[k]] <- pracma::nullspace(t(U[, k]))
}

fit_mo <- mo.bqr.svy(
  cbind(mpg, hp) ~ wt + cyl + disp,
  data     = mtcars,
  quantile = c(0.25, 0.5, 0.75),
  U        = U,
  gamma_U  = gamma_U,    
  prior    = my_prior,
  n_dir    = n_dir,
  max_iter = 5000,
  verbose  = FALSE
)

```

We can also fit several quantiles at once by passing a vector of probabilities with `c()`, for example `quantile = c(0.25, 0.5, 0.75)`.

### Model Output: Print and Summary Methods

There are also print() and summary() created for the output objects of bayesQRsurvey

We can explore the return of the object bqr.svy

```{r output-examples}
# Print method - shows basic model information
knitr::kable(
  data.frame(
    Information = c("Method", "Quantiles", "Draws", "Burn-in", "Thin"),
    Value = c(fit_ald$method, 
              paste(fit_ald$quantile, collapse = ", "),
              length(fit_ald$draws),
              fit_ald$warmup, 
              fit_ald$thin)
  ),
  caption = "Model Information - ALD Method"
)

# Summary method - detailed convergence diagnostics will be shown in summary section

# Access posterior draws - show structure
if (!is.null(fit_ald$draws)) {
  knitr::kable(
    head(as.data.frame(fit_ald$draws), 6),
    caption = "First 6 posterior draws (ALD Method)",
    digits = 4
  )
}
```

### Convergence Diagnostics

```{r convergence-diagnostics, results='asis'}
methods <- c("ALD", "Score", "Approximate")
fits <- list(fit_ald, fit_score, fit_approx)

summ_multi <- lapply(fits, summary)

summ_df <- do.call(rbind, lapply(seq_along(summ_multi), function(i) {
  s <- summ_multi[[i]]
  if (!is.null(s$posterior_summary)) {
    df <- as.data.frame(s$posterior_summary)
  } else if (!is.null(s$per_tau)) {
    df <- as.data.frame(s$per_tau[[1]]$coef_summary)
  } else {
    stop("Unexpected summary object structure")
  }
  df$Method <- methods[i]
  df
}))

summ_df <- summ_df[, c("Method", setdiff(names(summ_df), "Method"))]

knitr::kable(
  summ_df,
  caption = "Posterior summary for all methods (Quantile = 0.5)",
  digits = 3
)

```

### Visualization functions

The `bayesQRsurvey` package provides comprehensive visualization capabilities through its `plot()` method. The plotting system supports both **base R graphics** (default) and **ggplot2** (when `use_ggplot = TRUE`).

#### 1-. Fitted regression plot

Example plotting the fitted regression line using **ggplot2**, including the credible interval as a shaded band around the fitted line.

```{r basic-plot}
plot(fit_ald, use_ggplot = TRUE, show_ci  =TRUE)
```

It is possible to hide the points from the plot by setting the argument 
`add_points = FALSE`.

#### 2. Trace Plots

Example plotting the MCMC trace of a selected coefficient to assess convergence and mixing across iterations.


```{r quantile-plots}
# Basic quantile plot (requires x_var)
plot(fit_ald, type = "trace", x_var = "hp")
```

#### 3. Density Plots

Example plotting the posterior density of a selected coefficient, including the fitted quantile as a reference line.

```{r combined-plots}
# Combined view
plot(fit_ald, type = "density", x_var = "wt")
```

#### 4. Quantile Plots

Example plotting the estimated coefficient of a predictor across multiple quantiles.

```{r}
fit_multi <- bqr.svy(
  mpg ~ wt + hp + cyl,
  data = mtcars,
  quantile = seq(0.05, 0.95, 0.05),
  method = "ald",
  niter = 10000,
  burnin = 5000,
  thin = 5,
  verbose  = FALSE 
)

plot(fit_multi, type = "quantile", which = "(Intercept)")
```


#### 5. Multi-Panel Layouts

When working with multiple quantiles, it is often insightful to visualize how the fitted regression lines vary across different levels of the conditional distribution of the response.

```{r multi-panel}
# Fit model with multiple quantiles
fit_multi <- bqr.svy(mpg ~ wt + hp, data = mtcars, 
                     quantile = c(0.25, 0.5, 0.75), method = "ald",
                     niter = 5000, burnin = 2500, verbose = FALSE)
```
The `plot()` method in **bayesQRsurvey** makes this straightforward: by passing several quantiles in the `tau` argument, the function can overlay multiple fitted curves in the same plot.

```{r}
# Multi-panel coefficient plot
plot(fit_multi, type = "fit", use_ggplot = TRUE, ncol = 3, combine = TRUE)
```

Alternatively, the user may choose to display separate panels for each quantile by setting `combine = FALSE`.

```{r}
# Multi-panel coefficient plot
plot(fit_multi, type = "fit", use_ggplot = TRUE, ncol = 3, combine = FALSE)
```

## Comparison with bayesQR for the MCMC algorithms and EM algorithm 

### Simulation Study

We conduct a simulation study to illustrate **bayesQRsurvey** capabilities and compare with **bayesQR** using three different sampling designs: Poisson sampling, stratified sampling, and systematic sampling. Each design simulates complex survey data with known population parameters.

The used simulation functions can be found in the data-raw folder simulation.R file

```{r simulation-functions, include=FALSE}
# Load required packages for simulation
library(dplyr)
library(sampling)

# Function to generate Bernoulli random variables
rbern <- function(n, prob) {
  rbinom(n, 1, prob)
}

# Poisson sampling design - simulates unequal probability sampling
artificial_data_poi <- function(N, n) {
  resultado <- list()
  
  ## Population data
  xx        <- cbind(rep(1, N), runif(N, 0, 2))
  beta_sim  <- c(2, 1.5)  # True regression coefficients
  loc_sim   <- xx %*% beta_sim
  dados_pop <- NULL
  for(i in 1:N) {
    dados_pop[i] <- rnorm(1, loc_sim[i, 1], 1)
  }
  
  ## Sample data with Poisson sampling (weights depend on auxiliary variable)
  z_aux <- rnorm(N, mean = 1 + dados_pop, sd = 0.5)
  var_aux <- 1 / (1 + exp(2.5 - 0.5 * z_aux))
  probabilidades <- n * var_aux / sum(var_aux)
  w_pop <- 1 / probabilidades
  aux_aux <- NULL
  for(i in 1:N) {
    aux_aux[i] <- rbern(1, probabilidades[i])
  }
  dados <- dados_pop[which(aux_aux == 1)]
  x     <- xx[which(aux_aux == 1), ]
  w_aux <- w_pop[which(aux_aux == 1)]
  w     <- length(dados) * (w_aux / sum(w_aux))
  
  ## Final object
  resultado[['sample_data']] <- dados
  resultado[['x_matrix']]    <- x
  resultado[['weights']]     <- w
  resultado[['pop_data']]    <- dados_pop
  resultado[['x_pop']]       <- xx
  resultado[['weights_un']]  <- w_aux
  
  return(resultado)
}

# Stratified sampling design - simulates stratified survey
artificial_data_est <- function(N, n, n_est) {
  resultado <- list()
  
  ## Population data
  xx        <- cbind(rep(1, N), runif(N, 0, 2))
  beta_sim  <- c(2, 1.5)
  loc_sim   <- xx %*% beta_sim
  dados_pop <- NULL
  for(i in 1:N) {
    dados_pop[i] <- rnorm(1, loc_sim[i, 1], 1)
  }
  
  ## Sample data with stratified sampling
  z_aux <- rnorm(N, mean = 1 + dados_pop, sd = 0.5)
  var_aux <- 1 / (1 + exp(2.5 - 0.5 * z_aux))
  
  df     <- data.frame(cbind(dados_pop, xx, var_aux))
  colnames(df) <- c('y', 'x0', 'x1', 'z')
  
  # Create strata based on auxiliary variable
  df_ord <- df[order(df$z), ]
  df_ord$prop <- df_ord$z / sum(df_ord$z)
  df_ord$cprop <- cumsum(df_ord$prop)
  df_ord$bins <- cut(df_ord$cprop, breaks = n_est)
  df_ord$estrato <- factor(df_ord$bins, labels = c(1:n_est))
  
  n_k <- n / n_est
  s_aux <- sampling::strata(df_ord, c("estrato"), size = rep(n_k, n_est), method = "srswor")
  s <- sampling::getdata(df_ord, s_aux)
  s$w <- 1 / s$Prob
  
  ## Final object
  resultado[['sample_data']] <- s$y
  resultado[['x_matrix']]    <- cbind(s$x0, s$x1)
  resultado[['weights']]     <- length(s$y) * (s$w / sum(s$w))
  resultado[['pop_data']]    <- df$y
  resultado[['x_pop']]       <- cbind(df$x0, df$x1)
  resultado[['weights_un']]  <- s$w
  
  return(resultado)
}

# Systematic sampling design - simulates systematic survey sampling
artificial_data_sys <- function(N, n) {
  resultado <- list()
  
  ## Population data
  xx        <- cbind(rep(1, N), runif(N, 0, 2))
  beta_sim  <- c(2, 1.5)
  loc_sim   <- xx %*% beta_sim
  dados_pop <- NULL
  for(i in 1:N) {
    dados_pop[i] <- rnorm(1, loc_sim[i, 1], 1)
  }
  
  ## Sample data with systematic sampling
  z_aux <- rnorm(N, mean = 1 + dados_pop, sd = 0.5)
  var_aux <- 1 / (1 + exp(2.5 - 0.5 * z_aux))
  
  df           <- data.frame(cbind(dados_pop, xx, var_aux, rep(1, N)))
  colnames(df) <- c('y', 'x0', 'x1', 'z', 'estrato')
  s_aux <- sampling::strata(df, "estrato", size = n, method = "systematic", pik = df$z)
  s     <- sampling::getdata(df, s_aux)
  s$w   <- 1 / s$Prob
 
  ## Final object
  resultado[['sample_data']] <- s$y
  resultado[['x_matrix']]    <- cbind(s$x0, s$x1)
  resultado[['weights']]     <- length(s$y) * (s$w / sum(s$w))
  resultado[['pop_data']]    <- df$y
  resultado[['x_pop']]       <- cbind(df$x0, df$x1)
  resultado[['weights_un']]  <- s$w
  
  return(resultado)
}
```

#### Simulation Execution

We run the simulation function and obtain the following values

```{r simulation-study, results='asis'}
# Simulation parameters
set.seed(42)
N <- 10000  # Population size
n <- 500    # Sample size
n_est <- 5  # Number of strata for stratified sampling
quantiles <- c(0.25, 0.5, 0.75)

# True population parameters
true_beta <- c(2, 1.5)  # Intercept and slope

# Create simulation parameters table
sim_params <- data.frame(
  Parameter = c("Population size", "Sample size", "Number of strata", "Quantiles", "True β₀", "True β₁"),
  Value = c(N, n, n_est, paste(quantiles, collapse = ", "), true_beta[1], true_beta[2])
)

knitr::kable(sim_params, caption = "Simulation Study Parameters")

# Generate data for each sampling design
data_poi <- artificial_data_poi(N, n)
data_est <- artificial_data_est(N, n, n_est)
data_sys <- artificial_data_sys(N, n)

# Create data frames for analysis
create_dataframe <- function(sim_data) {
  data.frame(
    y = sim_data$sample_data,
    x = sim_data$x_matrix[, 2],  # Remove intercept column
    weights = sim_data$weights
  )
}

df_poi <- create_dataframe(data_poi)
df_est <- create_dataframe(data_est)
df_sys <- create_dataframe(data_sys)

# Sample sizes summary
sample_sizes <- data.frame(
  Design = c("Poisson", "Stratified", "Systematic"),
  Sample_Size = c(nrow(df_poi), nrow(df_est), nrow(df_sys))
)

knitr::kable(sample_sizes, caption = "Sample Sizes After Sampling", col.names = c("Design", "Sample Size"))
```

#### Method Comparison

```{r method-comparison, results='hide'}
# Function to fit models and extract coefficients
fit_and_compare <- function(data, design_name) {
  # Common MCMC settings (reduced for vignette)
  niter <- 5000
  burnin <- 2500
  
  # bayesQR
  fit_bqr <- bayesQR::bayesQR(
    y ~ x, 
    data = data,
    quantile = quantiles, 
    ndraw = niter - burnin,
    keep = 1
  )
  
  # bayesQRsurvey - ALD method
  fit_ald <- bqr.svy(
    y ~ x,
    data = data,
    weights = data$weights,
    quantile = quantiles,
    method = "ald",
    niter = niter,
    burnin = burnin,
    verbose  = FALSE 
  )
  
  # bayesQRsurvey - Score method
  fit_score <- bqr.svy(
    y ~ x,
    data = data,
    weights = data$weights,
    quantile = quantiles,
    method = "score", 
    niter = niter,
    burnin = burnin,
    verbose  = FALSE 
  )
  
  # bayesQRsurvey - Approximate method
  fit_approx <- bqr.svy(
    y ~ x,
    data = data,
    weights = data$weights,
    quantile = quantiles,
    method = "approximate",
    niter = niter,
    burnin = burnin,
    verbose  = FALSE
  )
  
  # Extract coefficient estimates
  coef_bqr <- sapply(1:3, function(i) colMeans(fit_bqr[[i]]$betadraw))
  coef_ald <- fit_ald$beta
  coef_score <- fit_score$beta
  coef_approx <- fit_approx$beta
  
  # Calculate bias and RMSE
  calculate_metrics <- function(estimates, true_vals) {
    bias <- estimates - matrix(rep(true_vals, 3), nrow = 2, ncol = 3)
    rmse <- sqrt(colMeans(bias^2))
    list(bias = bias, rmse = rmse, estimates = estimates)
  }
  
  metrics_bqr <- calculate_metrics(coef_bqr, true_beta)
  metrics_ald <- calculate_metrics(coef_ald, true_beta)
  metrics_score <- calculate_metrics(coef_score, true_beta)
  metrics_approx <- calculate_metrics(coef_approx, true_beta)
  
  return(list(
    bayesQR = metrics_bqr,
    ALD = metrics_ald,
    Score = metrics_score,
    Approximate = metrics_approx
  ))
}

# Run comparison for each design
results_poi <- fit_and_compare(df_poi, "Poisson")
results_est <- fit_and_compare(df_est, "Stratified")
results_sys <- fit_and_compare(df_sys, "Systematic")
```

#### Simulation Results

```{r , include=FALSE}
# Helper: create results table for a given design/quantile
create_results_table <- function(results, design_name, quantile_idx, tau_value) {
  methods <- names(results)
  
  # Extraer estimaciones para el cuantil dado
  estimates <- sapply(methods, function(m) results[[m]]$estimates[, quantile_idx])
  
  # Tabla comparativa
  comparison <- data.frame(
    Method     = methods,
    Intercept  = estimates[1, ],
    Slope      = estimates[2, ]
  )
  
  # Fila con los valores verdaderos
  true_row <- data.frame(
    Method     = "True Values",
    Intercept  = true_beta[1],
    Slope      = true_beta[2]
  )
  
  comparison <- rbind(true_row, comparison)
  rownames(comparison) <- NULL
  
  return(comparison)
}
```


```{r simulation-results-poisson, results='asis'}
# Poisson Sampling
for (q_idx in seq_along(quantiles)) {
  tau_val <- quantiles[q_idx]
  table_result <- create_results_table(
    results_poi, "Poisson", q_idx, tau_val
  )
  print(knitr::kable(
    table_result, digits = 4,
    caption = paste("Poisson Sampling - τ =", tau_val)
  ))
}
```

```{r simulation-results-stratified, results='asis'}
# Stratified Sampling
for (q_idx in seq_along(quantiles)) {
  tau_val <- quantiles[q_idx]
  table_result <- create_results_table(
    results_est, "Stratified", q_idx, tau_val
  )
  print(knitr::kable(
    table_result, digits = 4,
    caption = paste("Stratified Sampling - τ =", tau_val)
  ))
}
```


```{r simulation-results-systematic, results='asis'}
# Systematic Sampling
for (q_idx in seq_along(quantiles)) {
  tau_val <- quantiles[q_idx]
  table_result <- create_results_table(
    results_sys, "Systematic", q_idx, tau_val
  )
  print(knitr::kable(
    table_result, digits = 4,
    caption = paste("Systematic Sampling - τ =", tau_val)
  ))
}
```

For the EM algorithm

```{r}
library(pracma)
library(dplyr)
library(knitr)

#if (!exists("rbern")) rbern <- function(n, p) rbinom(n, 1, p)

make_mo_dataset <- function(design = c("poi","est","sys"),
                            N = 5000, n = 400, n_est = 4,
                            beta1 = c(2, 1.5),         
                            beta2 = c(-1, 0.8),       
                            sd2   = 1) {
  design <- match.arg(design)
  if (design == "poi") {
    s <- artificial_data_poi(N, n)
    X <- s$x_matrix            
    y1 <- as.numeric(s$sample_data)
    w  <- as.numeric(s$weights)
  } else if (design == "est") {
    s <- artificial_data_est(N, n, n_est)
    X <- s$x_matrix            
    y1 <- as.numeric(s$sample_data)
    w  <- as.numeric(s$weights)
  } else {
    s <- artificial_data_sys(N, n)
    X <- s$x_matrix            
    y1 <- as.numeric(s$sample_data)
    w  <- as.numeric(s$weights)
  }

  y2 <- as.numeric(X %*% beta2 + rnorm(nrow(X), sd = sd2))

  df <- data.frame(
    y1 = y1,
    y2 = y2,
    x1 = X[, 2]   
  )

  B <- cbind(beta1, beta2)  

  list(data = df, w = w, X = X, B = B)
}

```

```{r}
run_mo_sim <- function(design = "poi",
                       N = 5000, n = 400, n_est = 4,
                       taus = c(0.25, 0.5, 0.75),
                       n_dir = 10,
                       max_iter = 500, verbose = FALSE,
                       keep_intercept = FALSE) {
  sim <- make_mo_dataset(design = design, N = N, n = n, n_est = n_est)
  df  <- sim$data
  w   <- sim$w
  B   <- sim$B
  d   <- 2
  p   <- 2  

  set.seed(123)
  U <- matrix(NA_real_, d, n_dir)
  for (k in 1:n_dir) {
    uk <- rnorm(d)
    U[, k] <- uk / sqrt(sum(uk^2))
  }

  pr_mo <- prior(
    beta_x_mean = rep(0, p),
    beta_x_cov  = diag(1e6, p),
    sigma_shape = 0.001,
    sigma_rate  = 0.001,
    beta_y_mean = 0,
    beta_y_cov  = 1
  )

  fit <- mo.bqr.svy(
    cbind(y1, y2) ~ x1,
    data     = df,
    weights  = w,
    quantile = taus,
    U        = U,
    max_iter = max_iter,
    verbose  = verbose,
    prior    = pr_mo
  )

  qlab <- names(fit$fit)                 
  tau_vals <- as.numeric(gsub("tau=", "", qlab)) 
  tau_pick <- qlab[which.min(abs(tau_vals - 0.5))]

  stopifnot(tau_pick %in% qlab)

  comp <- do.call(rbind, lapply(1:n_dir, function(k) {
    Bu <- as.numeric(B %*% U[, k])        
    beta_hat <- fit$fit[[tau_pick]]$directions[[k]]$beta[1:p]

    if (keep_intercept) {
      data.frame(
        dir      = k,
        u1       = round(U[1, k], 4),
        u2       = round(U[2, k], 4),
        true_Int = Bu[1],
        true_x1  = Bu[2],
        hat_Int  = beta_hat[1],
        hat_x1   = beta_hat[2],
        row.names = NULL
      )
    } else {
      data.frame(
        dir     = k,
        u1      = round(U[1, k], 4),
        u2      = round(U[2, k], 4),
        true_x1 = Bu[2],
        hat_x1  = beta_hat[2],
        row.names = NULL
      )
    }
  }))

  list(fit = fit, U = U, B = B, comparison_tau0.5 = comp)
}

# Run simulation
out_poi2 <- run_mo_sim(
  design = "poi", N = 5000, n = 400, n_est = 4,
  taus = c(0.25, 0.5, 0.75), n_dir = 10,
  max_iter = 400, keep_intercept = TRUE
)

```


```{r}
kable(out_poi2$comparison_tau0.5,
      digits = 3,
      caption = "Directional comparison (tau = 0.5): true projected coefficients Bu vs. estimates from mo.bqr.svy.")
```


### Prostate Dataset

These data come from a study that examined the correlation between the level of prostate specific antigen and a number of clinical measures in men who were about to receive a radical prostatectomy. It is a data frame with 97 rows and 9 columns and is loaded form the bayesQR package.

```{r data-prep, results='asis'}
library(bayesQRsurvey)
library(bayesQR)

# Load Prostate dataset
data(Prostate, package = "bayesQR")

# Center covariates (subtract mean, don't scale)
covars <- Prostate[, colnames(Prostate) != "lpsa"]
covars_centered <- as.data.frame(scale(covars, center = TRUE, scale = FALSE))

# Combined dataset with centered covariates
Prostate_centered <- cbind(lpsa = Prostate$lpsa, covars_centered)

# Design matrix (includes intercept automatically)
X <- model.matrix(lpsa ~ ., data = Prostate_centered)
y <- Prostate_centered$lpsa
w <- rep(1, length(y))  # Equal weights

# Display dataset summary
dataset_info <- data.frame(
  Information = c("Observations", "Coefficients", "Response Variable", "Equal Weights"),
  Value = c(nrow(Prostate_centered), ncol(X), "lpsa (log prostate-specific antigen)", "Yes")
)

knitr::kable(dataset_info, caption = "Prostate Dataset Summary")

predictors_info <- data.frame(
  Predictor = colnames(X),
  Description = c("Intercept", paste("Centered", colnames(X)[-1]))
)

knitr::kable(predictors_info, caption = "Predictor Variables")
```



```{r priors, results='asis'}
# Prior for bayesQRsurvey (all methods)
prior_tbw <- bayesQRsurvey::prior(
  beta_x_mean = rep(0, ncol(X)),        
  beta_x_cov  = diag(1e6, ncol(X)),     
  sigma_shape = 0.001,                 
  sigma_rate  = 0.001                   
)


# Prior for bayesQR 
prior_bqr <- bayesQR::prior(
  lpsa ~ ., data = Prostate_centered,
  beta0 = rep(0, ncol(X)), 
  V0 = diag(1e6, ncol(X))  # Same vague prior
)
```


#### bayesQR (Reference Method)

```{r bayesQR-fit, results='hide'}
set.seed(12345)

fit_bqr <- bayesQR(
  lpsa ~ ., 
  data = Prostate_centered,
  quantile = c(0.25, 0.5, 0.75), 
  ndraw = 5000, 
  prior = prior_bqr, 
  keep = 5
)

taus <- c(0.25, 0.5, 0.75)

coef_mat <- do.call(rbind, lapply(seq_along(taus), function(i) {
  draws_i <- fit_bqr[[i]][["betadraw"]]
  colnames(draws_i) <- colnames(X)
  as.numeric(colMeans(draws_i, na.rm = TRUE))  # vector numérico
}))

rownames(coef_mat) <- paste0("tau = ", taus)
colnames(coef_mat) <- colnames(X)
```

#### bayesQRsurvey Method 1: ALD (Asymmetric Laplace Distribution)

```{r bayesQRsurvey-ald, results='hide'}
set.seed(12345)

fit_ald <- bqr.svy(
  lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
  data     = Prostate_centered,
  quantile = c(0.25, 0.5, 0.75),
  method   = "ald",
  prior    = prior_tbw,
  niter    = 50000,
  burnin   = 25000,
  thin     = 5,
  verbose  = FALSE 
)

coef_ald <- fit_ald$beta
```

#### bayesQRsurvey Method 2: Score Likelihood

```{r bayesQRsurvey-score, results='hide'}
set.seed(12345)

fit_score <- bqr.svy(
  lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
  data     = Prostate_centered,
  quantile = c(0.25, 0.5, 0.75),
  method   = "score",
  prior    = prior_tbw,
  niter    = 50000,
  burnin   = 25000,
  thin     = 5,
  verbose  = FALSE 
)

coef_score <- fit_score$beta
```

#### bayesQRsurvey Method 3: Approximate Method

```{r bayesQRsurvey-approximate, results='hide'}
set.seed(12345)

fit_approximate <- bqr.svy(
  lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
  data     = Prostate_centered,
  quantile = c(0.25, 0.5, 0.75),
  method   = "approximate",
  prior    = prior_tbw,
  niter    = 50000,
  burnin   = 25000,
  thin     = 5,
  verbose  = FALSE 
)

coef_approximate <- fit_approximate$beta
```

#### Results comparison

```{r}
make_results_table <- function(q_index, q_label) {
  coef_bqr   <- coef_mat[q_index, ]
  coef_ald   <- fit_ald[["beta"]][, q_index]
  coef_score <- fit_score[["beta"]][, q_index]
  coef_approx<- fit_approximate[["beta"]][, q_index]
  
  vars <- names(coef_bqr)
  
  results <- data.frame(
    Method = c("bayesQR", "bayesQRsurvey - ALD", "bayesQRsurvey - Score", "bayesQRsurvey - Approximate"),
    t(sapply(list(coef_bqr, coef_ald, coef_score, coef_approx), function(coefs) coefs[vars]))
  )
  
  colnames(results) <- c("Method", vars)
  
  knitr::kable(results, digits = 3, caption = paste("Coefficient Estimates at quantile", q_label))
}
```

##### 25th quantile

```{r Comparison}
make_results_table(1, 0.25)
```

##### 50th quantile

```{r}
make_results_table(2, 0.50)
```

##### 75th quantile

```{r}
make_results_table(3, 0.75)
```
