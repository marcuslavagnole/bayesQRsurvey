---
title: "tauBayesW: Bayesian Weighted Quantile Regression"
author: "Tomas Rodriguez Taborda"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tauBayesW}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

<p align="center">
  <img src="logo_tau.png" width="180" alt="tauBayesW logo"/>
</p>

# tauBayesW: An R Framework for Bayesian Weighted Quantile Regression

[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/tauBayesW)](https://cran.r-project.org/package=tauBayesW)
[![downloads](https://cranlogs.r-pkg.org/badges/tauBayesW)](https://cran.r-project.org/package=tauBayesW)

## What is tauBayesW?

**tauBayesW** is an R package that provides a comprehensive framework for Bayesian weighted quantile regression with survey designs. The package implements MCMC and EM algorithms to handle complex survey data while maintaining computational efficiency using a C++ backend. Some of its key features include:

- **Handles survey weights naturally** under a Bayesian framework
- **Implements multiple MCMC methods** (ALD, Score, Approximate)  
- **Estimates multiple quantiles efficiently** using EM algorithms
- **Provides comprehensive visualization** tools
- **Includes model diagnostics** and convergence checking

## Installation

```{r}
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
```


```{r installation, eval=FALSE}
# From CRAN (when available)
#install.packages("tauBayesW")

# From GitHub (development version)
remotes::install_github("torodriguezt/tauBayesW")
```

```{r setup}
library(tauBayesW)
set.seed(123)
```

## Citation

To cite tauBayesW in publications, please use:

```{r citation, eval=FALSE}
citation("tauBayesW")
```

## Getting Started

tauBayesW provides two main functions to fit a bayesian quantile regression model with survey weights using MCMC and EM algorithms, also each of them has a plotting function to visualize the results and a summary method to extract key information:

- **`bqr.svy()`**: 🎯 Bayesian quantile regression for multiple quantiles with survey weights using MCMC algorithms
- **`mo.bqr.svy()`**: 📊 Bayesian multivariate and multidirectional quantile regression for multiple quantiles with survey weights using Expected Maximization algorithm
- **`plot_quantile()`**: 🎨 Comprehensive visualization functions for quantile regression

### Basic Usage

Let's start with a simple example using survey data for the MCMC algorithms:

```{r basic-example}
# Simulate survey data with design weights
n <- 500
x1 <- rnorm(n)
x2 <- rbinom(n, 1, 0.4)
y <- 1 + 2*x1 + 1.5*x2 + rnorm(n)
weights <- runif(n, 0.5, 2)  # Survey weights

data <- data.frame(y, x1, x2)

# Single quantile regression (median)
model_median <- bqr.svy(y ~ x1 + x2, 
                        data = data,
                        weights = weights,
                        quantile = 0.5,
                        niter = 2000,
                        burnin = 500,
                        verbose = FALSE)

```


```{r}
print(model_median)
```

```{r}
summary(model_median)
```

And using the EM algorithm

```{r}
model_median <- mo.bqr.svy(y ~ x1 + x2, 
                        data = data,
                        weights = weights,
                        quantile = 0.5,
                        max_iter = 2000,
                        epsilon = 1e-8,
                        verbose = FALSE)
```


```{r}
print(model_median)
```
```{r}
summary(model_median)
```


### Multiple quantiles

tauBayesW implements three different MCMC approaches, all of them allow to fit more than one quantile with only one call:

```{r mcmc-methods}
n <- 800
x1 <- runif(n)
x2 <- rnorm(n)
y <- 3 + 2*x1 + 1.5*x2 + rnorm(n)
weights <- rep(1, n)
data <- data.frame(y, x1, x2)

methods <- c("ald", "score", "approximate")
results <- list()

model_ald <- bqr.svy(y ~ x1 + x2,
                               data = data,
                               weights = weights,
                               quantile = c(0.5, 0.95),
                               method = "ald",
                               n_mcmc = 60000,
                               burnin = 25000,
                               verbose = FALSE)

summary(model_ald)

model_score <- bqr.svy(y ~ x1 + x2,
                               data = data,
                               weights = weights,
                               quantile = c(0.5, 0.95),
                               method = "score",
                               n_mcmc = 60000,
                               burnin = 25000,
                               verbose = FALSE)

summary(model_score)


model_approximate <- bqr.svy(y ~ x1 + x2,
                               data = data,
                               weights = weights,
                               quantile = c(0.5, 0.95),
                               method = "approximate",
                               n_mcmc = 60000,
                               burnin = 25000,
                               verbose = FALSE)

summary(model_approximate)

```



For the Expected-Maximization Algorithm

```{r multiple-quantiles}
# Multiple quantiles simultaneously
quantiles <- c(0.1, 0.25, 0.5, 0.75, 0.9)

model_em<- mo.bqr.svy(y ~ x1 + x2,
                               data = data,
                               weights = weights,
                               quantile = c(0.5, 0.95),
                               method = "approximate",
                               max_iter = 1500,
                               epsilon = 1e-6,
                               verbose = FALSE)

summary(model_em)
```

### Visualization

```{r visualization, fig.width=8, fig.height=6}
n_vis <- 300
x_vis <- seq(-2, 2, length.out = n_vis)
y_vis <- 1 + 2*x_vis + (0.5 + 0.3*abs(x_vis))*rnorm(n_vis) 
weights_vis <- rgamma(n_vis, 2, 1)
data_vis <- data.frame(y = y_vis, x = x_vis)

# Fit single quantile for plotting
model_vis <- bqr.svy(y ~ x, 
                     data = data_vis,
                     weights = weights_vis,
                     quantile = 0.5,
                     niter = 2000,
                     burnin = 500,
                     verbose = FALSE)

# Plot quantile regression with data points
plot_quantile_with_points.bqr.svy(model_vis, data = data_vis, predictor = "x",
                          point_alpha = 0.6,
                          main = "Bayesian Quantile Regression (τ = 0.5)")
```


```{r}
n_vis <- 300
x_vis <- seq(-2, 2, length.out = n_vis)
y_vis <- 1 + 2*x_vis + (0.5 + 0.3*abs(x_vis))*rnorm(n_vis) 
weights_vis <- rgamma(n_vis, 2, 1)
data_vis <- data.frame(y = y_vis, x = x_vis)

# Fit single quantile for plotting
model_vis <- mo.bqr.svy(y ~ x, 
                        data = data_vis,
                        weights = weights_vis,
                        quantile = 0.5,
                        max_iter = 2000,
                        epsilon = 1e-8,
                        verbose = FALSE)

# Plot quantile regression with data points
plot_quantile_with_points.mo.bqr.svy(model_vis, data = data_vis, predictor = "x",
                          point_alpha = 0.6,
                          main = "Bayesian Quantile Regression (τ = 0.5)")
```



#### Multiple Quantile Visualization

```{r multi-quantile-viz, fig.width=8, fig.height=6}
# Fit multiple quantiles for univariate case
model_multi_vis <- mo.bqr.svy(y ~ x,
                              data = data_vis,
                              weights = weights_vis,
                              quantile = c(0.1, 0.25, 0.5, 0.75, 0.9),
                              max_iter = 1000,
                              verbose = FALSE)

# Plot multiple quantile curves
plot(model_multi_vis, type = "quantiles")

# Plot coefficient evolution across quantiles  
plot(model_multi_vis, type = "convergence")

```


### Prior information

We can also use informative prior distributions

For the MCMC case

```{r}
# ---------------------
# Example data
# ---------------------
set.seed(123)
n  <- 200
x1 <- rnorm(n)
x2 <- rnorm(n)
w  <- runif(n, 0.5, 2)   # weights
tau <- 0.5               # target quantile

y <- 1 + 2 * x1 - 1.5 * x2 + rnorm(n)

data_ex <- data.frame(y, x1, x2, w)

# ---------------------
# Informative prior
# ---------------------
prior_info <- prior_default(
  p     = 3,
  b0    = c(0, 1.5, -1.0),          # prior means
  B0    = diag(c(0.5, 0.25, 0.25)), # small variances => more concentrated prior
  c0    = 2,                        # hyperparameter for ALD (more informative than 0.001)
  C0    = 1,
  names = c("(Intercept)", "x1", "x2")
)

# ---------------------
# Fit with the 3 methods
# ---------------------

# ALD method
fit_ald <- bqr.svy(
  formula  = y ~ x1 + x2,
  weights  = w,
  data     = data_ex,
  quantile = tau,
  method   = "ald",
  prior    = prior_info,
  niter    = 2000,
  burnin   = 500,
  thin     = 5
)

# Score method
fit_score <- bqr.svy(
  formula  = y ~ x1 + x2,
  weights  = w,
  data     = data_ex,
  quantile = tau,
  method   = "score",
  prior    = prior_info,
  niter    = 2000,
  burnin   = 500,
  thin     = 5
)

# Approximate method
fit_ap <- bqr.svy(
  formula  = y ~ x1 + x2,
  weights  = w,
  data     = data_ex,
  quantile = tau,
  method   = "approximate",
  prior    = prior_info,
  niter    = 2000,
  burnin   = 500,
  thin     = 5
)

# ---------------------
# Results
# ---------------------
cat("\n--- ALD ---\n")
print(fit_ald$beta)

cat("\n--- Score ---\n")
print(fit_score$beta)

cat("\n--- Approximate ---\n")
print(fit_ap$beta)

```

For the EM algorithm


```{r}
# ---------------------
# Example data
# ---------------------
set.seed(456)
n <- 150
p <- 2  # number of predictors (excluding intercept)

# Simulated predictors
x1 <- rnorm(n)
x2 <- rnorm(n)
w  <- runif(n, 0.5, 2)   # survey weights

# True model: intercept + slopes
y <- 1 + 1.8 * x1 - 1.2 * x2 + rnorm(n, 0, 1)

data_ex <- data.frame(y, x1, x2, w)

# ---------------------
# Informative prior for mo.bqr.svy
# ---------------------
prior_info <- mo_prior_default(
  p           = 3,                             # intercept + 2 slopes
  beta_mean   = c(0.5, 1.5, -1.0),              # prior means
  beta_cov    = diag(c(0.2, 0.15, 0.15)),       # small variances -> concentrated prior
  sigma_shape = 2,                              # more informative than 0.001
  sigma_rate  = 1,
  names       = c("(Intercept)", "x1", "x2")
)

# ---------------------
# Fit model with EM algorithm
# ---------------------
fit_mo <- mo.bqr.svy(
  formula   = y ~ x1 + x2,
  weights   = w,
  data      = data_ex,
  quantile  = c(0.25, 0.5, 0.75),  # multiple quantiles
  algorithm = "em",
  prior     = prior_info,
  max_iter  = 1000,
  epsilon   = 1e-6,
  verbose   = FALSE
)

# ---------------------
# Results
# ---------------------
print(fit_mo)

# Access coefficients for each quantile
for (q in seq_along(fit_mo$quantile)) {
  cat(sprintf("\nQuantile %.2f coefficients:\n", fit_mo$quantile[q]))
  print(fit_mo$fit[[q]]$beta)
}

```

### Multivariate and multidirectional case

The EM algorithm implementation allows to fit a multivariate and multidirectional model passing multiple quantiles

```{r}
library(tauBayesW)

set.seed(1)
n  <- 1200
x1 <- rnorm(n)
x2 <- rnorm(n)
X  <- cbind(1, x1, x2)

# Coeficientes "verdaderos" para cada componente de Y
B <- rbind(
  c( 1.00,  2.00, -0.50),  # y1
  c(-0.50,  1.20,  0.80),  # y2
  c( 0.30, -1.10,  0.20)   # y3
)

# Ruido (no tiene que ser ALD para este ejemplo)
eps <- cbind(rnorm(n, 0, 0.6),
             rnorm(n, 0, 0.6),
             rnorm(n, 0, 0.6))

Y <- X %*% t(B) + eps
colnames(Y) <- c("y1","y2","y3")

data <- data.frame(y1 = Y[,1], y2 = Y[,2], y3 = Y[,3], x1 = x1, x2 = x2)

# Pesos de muestreo (opcionales)
weights <- rexp(n, rate = 1)
weights <- weights / mean(weights)  # normalizo por comodidad

# Cuantiles a usar en los ejemplos
quantiles <- c(0.5, 0.75) 
```

#### Multivariate unidirectional

```{r}
model_uni_dir <- mo.bqr.svy(
  cbind(y1, y2, y3) ~ x1 + x2,
  data      = data,
  weights   = weights,
  quantile  = quantiles,   # aquí 0.5
  n_dir     = 1,           # UNA dirección
  r         = 0,           # sin Gamma
  em_mode   = "separable", # separable: betas por dirección (aquí K=1)
  max_iter  = 1200,
  verbose   = FALSE
)

print(model_uni_dir)
summary(model_uni_dir)
```

### Multivariate multidirectional

```{r}
K_dirs <- 60  # número típico de direcciones en S^2

model_multi_dirs <- mo.bqr.svy(
  cbind(y1, y2, y3) ~ x1 + x2,
  data      = data,
  weights   = weights,
  quantile  = quantiles,   # 0.5
  n_dir     = K_dirs,      # muchas direcciones
  r         = 0,           # sin Gamma (poliedro definido sólo por betas_X)
  em_mode   = "separable", # estable y rápido
  max_iter  = 2000,
  verbose   = FALSE
)

print(model_multi_dirs)
summary(model_multi_dirs)
```

#### Multivariate Multidirectional (r>0)

```{r}
K_dirs_r <- 50

model_multi_dirs_r <- mo.bqr.svy(
  cbind(y1, y2, y3) ~ x1 + x2,
  data      = data,
  weights   = weights,
  quantile  = quantiles,    # 0.5 (puedes poner varios)
  n_dir     = K_dirs_r,     # muchas direcciones
  r         = 2,            # <-- usa 2 dimensiones ortogonales por dirección
  em_mode   = "separable",  # betas por dirección + gammas por dirección
  max_iter  = 2000,
  verbose   = FALSE
)

print(model_multi_dirs_r)
summary(model_multi_dirs_r)
```


## Joint vs. Separable and the Role of *r*

In multivariate quantile regression with directional EM estimation, two key modeling choices are:

1. **Mode**: whether coefficients are fit in a *separable* way (each direction has its own parameters) or in a *joint* way (a single set of parameters shared across directions).  
2. **Orthogonal dimension `r`**: how many extra “orthogonal” directions are included per quantile surface, beyond the main projection.

---

### Separable mode

- In *separable* mode, each direction \( u_k \) is fit with its own coefficient vector.  
- This means the model can flexibly adapt to directional asymmetry.  
- Since the data live in a \(d\)-dimensional response space, each direction already consumes one dimension. The maximum number of orthogonal components is therefore \( d - 1 \).  

```{r}
model_joint <- mo.bqr.svy(
  cbind(y1, y2, y3) ~ x1 + x2,
  data      = data,
  weights   = weights,
  quantile  = 0.5,
  n_dir     = 40,        
  r         = 0,        
  em_mode   = "joint",   
  max_iter  = 800,
  verbose   = FALSE
)

# Ajuste con modo separable
model_sep <- mo.bqr.svy(
  cbind(y1, y2, y3) ~ x1 + x2,
  data      = data,
  weights   = weights,
  quantile  = 0.5,
  n_dir     = 40,        
  r         = 2,
  em_mode   = "separable", 
  max_iter  = 800,
  verbose   = FALSE
)

# Comparar resúmenes
summary(model_joint)
summary(model_sep)
```


#### Visualization 3D

```{r}
p3d <- plot_quantile_body3d.mo.bqr.svy(
    object       = model_multi_dirs,
    tau          = 0.5,                     
    data         = data,                   
    fixed_values = list(x1 = 0, x2 = 0),     
    engine       = "plotly",
    col          = "#1f77b4",
    opacity      = 0.6,
    show_points  = TRUE
  )
p3d
```



## Methodology

### Theoretical Background

The package implements Bayesian quantile regression using the **Asymmetric Laplace Distribution (ALD)** representation:

$$y_i \sim ALD(\mu_i, \sigma, \tau)$$

where $\mu_i = \mathbf{x}_i^T \boldsymbol{\beta}$ and the likelihood is:

$$f(y_i|\mu_i,\sigma,\tau) = \frac{\tau(1-\tau)}{\sigma} \exp\left(-\rho_\tau\left(\frac{y_i-\mu_i}{\sigma}\right)\right)$$

The check function $\rho_\tau(u) = u(\tau - \mathbb{I}(u < 0))$ naturally incorporates quantile-specific loss.

### Survey Weights Integration

Survey weights $w_i$ are naturally incorporated in the Bayesian framework through the weighted likelihood:

$$L(\boldsymbol{\beta}, \sigma) = \prod_{i=1}^n f(y_i|\mu_i, \sigma, \tau)^{w_i}$$

This approach maintains design consistency while providing full posterior inference.

### EM Algorithm for Multiple Quantiles

The package implements an EM algorithm that:

1. **E-step**: Computes posterior expectations of latent variables
2. **M-step**: Updates parameters via weighted optimization

Both MCMC and EM algorithms ensures:
- Computational efficiency
- Numerical stability  

## Simulation and Validation

```{r simulation}
# Built-in simulation function
sim_data <- simulate_mo_bqr_data(n = 700,
                                 beta = c(1, 2, -0.5),
                                 seed = 456)

# Fit model to simulated data
sim_model <- mo.bqr.svy(y ~ x1 + x2,
                        data = sim_data$data,
                        weights = sim_data$weights,
                        quantile = c(0.25, 0.5, 0.75),
                        verbose = FALSE)

# Compare true vs estimated coefficients
true_coefs <- c(1, 2, -0.5)
estimated_coefs <- sim_model$fit$q0.5

print("True coefficients:")
print(true_coefs)
print("Estimated coefficients quantile 0.5:")
print(estimated_coefs) 
```

## Additional Documentation

For comprehensive documentation, examples, and advanced tutorials, visit:

**📖 [https://torodriguezt.github.io/tauBayesW/](https://torodriguezt.github.io/tauBayesW/)**

## Dependencies

tauBayesW is designed to be lightweight with minimal dependencies:

- **Base R packages**: stats, grDevices, graphics
- **C++ integration**: Rcpp, RcppEigen, RcppArmadillo
- **Suggested**: survey (for complex survey examples)
- **plotly**: for interactive 3d graphics

This makes tauBayesW safe to use as a dependency in other packages without dependency conflicts.

## Package Functions Overview

| Function | Purpose | Type |
|----------|---------|------|
| `bqr.svy()` | Single quantile regression | Main |
| `mo.bqr.svy()` | Multiple quantile regression | Main |
| `plot_quantile()` | Quantile curve visualization | Plotting |
| `plot_quantile_with_points()` | Scatter plot with quantile overlay | Plotting |
| `convergence_check()` | MCMC convergence diagnostics | Diagnostic |
| `simulate_mo_bqr_data()` | Data simulation for testing | Utility |


## References
- Nascimento, M. L., & Gonçalves, K. C. M. (2024). Bayesian Quantile Regression Models for Complex Survey Data Under Informative Sampling. Journal of Survey Statistics and Methodology, 12(4), 1105–1130. https://doi.org/10.1093/jssam/smae015

- Yu, K. and Moyeed, R. A. (2001). Bayesian quantile regression. Statistics & Probability Letters, 54(4), 437-447.
---
